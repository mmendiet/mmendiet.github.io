<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Matias Mendieta</title>
  
  <meta name="author" content="Matias Mendieta">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Matias Mendieta</name>
              </p>
              <!-- <p style="font-size:15px"> -->
              <p> 
                I am a Ph.D. student in the <a href=https://www.crcv.ucf.edu>Center for Research in Computer Vision</a> at the University of Central Florida, advised by <a href=https://webpages.uncc.edu/cchen62>Dr. Chen Chen</a>. My research interests are in the areas of machine learning, computer vision, and autonomous systems. 
              </p>
              <!-- <p> -->
                <!-- I have a broad interest in deep learning and computer vision. My current research mainly focuses on large model adaptation, efficient neural networks, runtime adaptive networks, representation learning and its applications on image and video understanding. -->
              <!-- </p> -->
              <!-- <p> My works have been selected as CVPR Best Paper Finalist (2022) and ICCV Oral Presentation (2023). </p> -->
              <p style="text-align:center">
                <a href="mailto:matias.mendieta@ucf.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=iO5zyPwAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/mmendiet">Github</a> &nbsp/&nbsp
                <a href="http://www.linkedin.com/in/matias-mendieta">LinkedIn</a> &nbsp/&nbsp
                <a href="data/CV_website.pdf">CV</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/matias.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/matias_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Intern Experience</heading>
            </td>
          </tr>
          </table>

          <table width="100%" align="center" border="0" cellpadding="20"></tbody>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/apple2.png' width="110">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <strong>Machine Learning Intern</strong>
                <br> Apple
                <br> Cupertino, CA. May 2023 - Aug. 2023
                <!-- <br> Host: <a href="https://bryanyzhu.github.io/">Yi Zhu</a>,
                <a href="https://www.amazon.science/author/yusheng-xie">Yusheng Xie</a>,
                <a href="https://www.astonzhang.com/">Aston Zhang</a>,
                <a href="https://scholar.google.com/citations?user=Z_WrhK8AAAAJ&hl=en">Mu Li</a> -->
                <p></p>
                <p> Investigated generative AI methods for image and video inpainting.</p>
              </td>
            </tr>
          </tr>
          </table>

          <table width="100%" align="center" border="0" cellpadding="20"></tbody>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/aws.jpg' width="110">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <strong>Applied Scientist Intern</strong>
                <br> Amazon AWS
                <br> Santa Clara, CA. May 2022 - Nov. 2022
                <!-- <br> Host: <a href="https://bryanyzhu.github.io/">Yi Zhu</a>,
                <a href="https://www.amazon.science/author/yusheng-xie">Yusheng Xie</a>,
                <a href="https://www.astonzhang.com/">Aston Zhang</a>,
                <a href="https://scholar.google.com/citations?user=Z_WrhK8AAAAJ&hl=en">Mu Li</a> -->
                <p></p>
                <p> Conducted computer vision research in self-supervised learning for geospatial foundation models.</p>
              </td>
            </tr>
          </tr>
          </table>

          <table width="100%" align="center" border="0" cellpadding="20"></tbody>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/ibm.png' width="120">
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <strong>Software Engineer Intern</strong>
                <br> IBM
                <br> Durham, NC. May 2018 - Aug. 2018
                <!-- <br> Host: <a href="https://sites.google.com/site/linjieyang89/">Linjie Yang</a>, -->
                <!-- <a href="https://scholar.google.com.sg/citations?user=OEZ816YAAAAJ&hl=en">Xiaojie Jin</a> -->
                <p></p>
                <p>Designed, integrated, and tested full proxy functionality for a SASP load balancer simulator.</p>
              </td>
            </tr>
          </tr>
          </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="mira_stop()" onmouseover="mira_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='mira_image'> -->
                  <!-- <img src='images/FedPEFT.JPG' width="160"></div> -->
                <img src='images/gfm.PNG' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2302.04476">
                <papertitle>Towards Geospatial Foundation Models via Continual Pretraining</papertitle>
              </a>
              <br>
              <strong>Matias Mendieta</strong>,
              Boran Han,
              Xingjian Shi,
              Yi Zhu,
              Chen Chen.
              <br>
              <em>International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2302.04476">arXiv</a> &nbsp/&nbsp
              <a href="https://github.com/mmendiet/GFM">code</a>
              <p></p>
              <!-- <p>
                A new comprehensive action recognition benchmark to evaluate spatiotemporal representation learning from various perspectives.
              </p> -->
            </td>
          </tr>
				
          <tr onmouseout="mira_stop()" onmouseover="mira_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='mira_image'> -->
                  <!-- <img src='images/FedPEFT.JPG' width="160"></div> -->
                <img src='images/pgfed.png' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2212.01448">
                <papertitle>PGFed: Personalize Each Client‚Äôs Global Objective for Federated Learning</papertitle>
              </a>
              <br>
              Jun Luo,
              <strong>Matias Mendieta</strong>,
              Chen Chen,
              Shandong Wu,
              <br>
              <em>International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2023
              <br><em><strong><font color="red">Oral Presentation</font></strong></em>
              <br>
              <a href="https://arxiv.org/pdf/2302.03024.pdf">arXiv</a> &nbsp/&nbsp
              <!-- <a href="https://adapt-image-models.github.io/">project</a> &nbsp/&nbsp -->
              <a href="https://github.com/ljaiverson/pgfed">code</a>
              <p></p>
              <!-- <p> -->
                <!-- How to efficiently and effectively adapt image models for video understanding. -->
              <!-- </p> -->
            </td>
          </tr>

          <tr onmouseout="mira_stop()" onmouseover="mira_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='mira_image'> -->
                  <!-- <img src='images/FedPEFT.JPG' width="160"></div> -->
                <img src='images/fedperfix.png' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2308.09160">
                <papertitle>FedPerfix: Towards Partial Model Personalization of Vision Transformers in Federated Learning</papertitle>
              </a>
              <br>
              Guangyu Sun,
              <strong>Matias Mendieta</strong>,
              Jun Luo,
              Shandong Wu,
              Chen Chen.
              <br>
              <em>International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2023
              <br>
              <a href="https://arxiv.org/pdf/2211.08666.pdf">arXiv</a>
              <!-- <a href="https://github.com/taoyang1122/Revisit_TrainingFree_NAS">code</a> -->
              <p></p>
              <!-- <p>
                Training-free metrics are highly correlated with #params and we propose a new efficient training-based method to address the problem.
              </p> -->
            </td>
          </tr>

          <tr onmouseout="mira_stop()" onmouseover="mira_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='mira_image'> -->
                  <!-- <img src='images/FedPEFT.JPG' width="160"></div> -->
                <img src='images/poster.png' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2204.04083">
                <papertitle>POSTER: A Pyramid Cross-Fusion Transformer Network for Facial Expression Recognition</papertitle>
              </a>
              <br>
              Ce Zheng,
              <strong>Matias Mendieta</strong>,
              Chen Chen.
              <br>
              <em>International Conference on Computer Vision (<strong>ICCV</strong>) AMFG Workshop</em>, 2023.
              <br>
              <a href="https://arxiv.org/abs/2204.04083">arXiv</a> &nbsp/&nbsp
              <a href="https://github.com/zczcwh/POSTER">code</a>
              <p></p>
              <!-- <p>
                Training-free metrics are highly correlated with #params and we propose a new efficient training-based method to address the problem.
              </p> -->
            </td>
          </tr>

          <tr onmouseout="mira_stop()" onmouseover="mira_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='mira_image'> -->
                  <!-- <img src='images/FedPEFT.JPG' width="160"></div> -->
                <img src='images/feater.JPG' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2205.15448">
                <papertitle>FeatER: An Efficient Network for Human Reconstruction via Feature Map-Based Transformer</papertitle>
              </a>
              <br>
              Ce Zheng,
              <strong>Matias Mendieta</strong>,
              TaoJinnan Yang,
              Guo-Jun Qi,
              Chen Chen.
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2205.15448">arXiv</a> &nbsp/&nbsp
              <a href="https://github.com/zczcwh/FeatER">code</a>
              <p></p>
              <!-- <p>
                Training-free metrics are highly correlated with #params and we propose a new efficient training-based method to address the problem.
              </p> -->
            </td>
          </tr>

          <tr onmouseout="mira_stop()" onmouseover="mira_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='mira_image'> -->
                  <!-- <img src='images/FedPEFT.JPG' width="160"></div> -->
                <img src='images/fedalign.JPG' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2111.14213.pdf">
                <papertitle>Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning</papertitle>
              </a>
              <br>
            <strong>Matias Mendieta</strong>,
              Taojiannan Yang,
              Pu Wang, 
              Minwoo Lee, 
              Zhengming Ding, 
              Chen Chen.
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2022 
              <br><em><strong><font color="red">Best Paper Finalist, 33 out of 8161</font></strong></em>
              <br>
              <a href="https://arxiv.org/pdf/2111.14213.pdf">arXiv</a> &nbsp/&nbsp
              <a href="https://github.com/mmendiet/FedAlign">code</a>
              <p></p>
              <!-- <p>
                GradAug alleviates data heterogeneity in federated learning by smoothing loss landscape. We further improve its efficiency by proposing a new method FedAlign.
              </p> -->
            </td>
          </tr>

          <tr onmouseout="mira_stop()" onmouseover="mira_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='mira_image'> -->
                  <!-- <img src='images/FedPEFT.JPG' width="160"></div> -->
                <img src='images/gtrs.png' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2111.12696">
                <papertitle>A Lightweight Graph Transformer Network for Human Mesh Reconstruction from 2D Human Pose</papertitle>
              </a>
              <br>
              Ce Zheng,
              <strong>Matias Mendieta</strong>,
              Pu Wang,
              Aidong Lu,
              Chen Chen.
              <br>
              <em>ACM Multimedia (<strong>ACM-MM</strong>)</em>, 2022.
              <br>
              <a href="https://arxiv.org/abs/2111.12696">arXiv</a> &nbsp/&nbsp
              <a href="https://github.com/zczcwh/GTRS">code</a>
              <p></p>
              <!-- <p>
                Training-free metrics are highly correlated with #params and we propose a new efficient training-based method to address the problem.
              </p> -->
            </td>
          </tr>

          <tr onmouseout="mira_stop()" onmouseover="mira_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='mira_image'> -->
                  <!-- <img src='images/FedPEFT.JPG' width="160"></div> -->
                <img src='images/MutualNet-tpami.JPG' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2105.07085">
                <papertitle>MutualNet: Adaptive ConvNet via Mutual Learning from Different Model Configurations</papertitle>
              </a>
              <br>
              Taojiannan Yang,
              Sijie Zhu, 
              <strong>Matias Mendieta</strong>, 
              Pu Wang, 
              Ravikumar Balakrishnan, 
              Minwoo Lee, 
              Tao Han, 
              Mubarak Shah, 
              Chen Chen.
              <br>
              <em>IEEE Transaction on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)</em>, 2021
              <br>
              <a href="https://arxiv.org/abs/2105.07085">arXiv</a> &nbsp/&nbsp
              <a href="https://github.com/taoyang1122/MutualNet">code</a>
              <p></p>
              <!-- <p>
                We extend MutualNet to learn adaptive video models and conduct more analyses.
              </p> -->
            </td>
          </tr>

          <tr onmouseout="mira_stop()" onmouseover="mira_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='mira_image'> -->
                  <!-- <img src='images/FedPEFT.JPG' width="160"></div> -->
                <img src='images/carpe.png' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2005.12469">
                <papertitle>CARPe Posterum: A Convolutional Approach for Real-time Pedestrian Path Prediction</papertitle>
              </a>
              <br>
              <strong>Matias Mendieta</strong>,
              Hamed Tabkhi.
              <br>
              <em>Association for the Advancement of Artificial Intelligence (<strong>AAAI</strong>)</em>, 2021
              <br>
              <a href="https://arxiv.org/abs/2005.12469">arXiv</a> &nbsp/&nbsp
              <a href="https://github.com/TeCSAR-UNCC/CARPe_Posterum">code</a>
              <p></p>
              <!-- <p>
                A spatial-temporal transformer structure for 3D human pose estimation.
              </p> -->
            </td>
          </tr>

          <tr onmouseout="mira_stop()" onmouseover="mira_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='mira_image'> -->
                  <!-- <img src='images/FedPEFT.JPG' width="160"></div> -->
                <img src='images/poseformer.JPG' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2103.10455">
                <papertitle>3D Human Pose Estimation with Spatial and Temporal Transformers </papertitle>
              </a>
              <br>
              Ce Zheng, 
              Sijie Zhu, 
              <strong>Matias Mendieta</strong>,
              Taojiannan Yang,
              Chen Chen, 
              Zhengming Ding.
              <br>
              <em>International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2021
              <br>
              <a href="https://arxiv.org/abs/2103.10455">arXiv</a> &nbsp/&nbsp
              <a href="https://github.com/zczcwh/PoseFormer">code</a>
              <p></p>
              <!-- <p>
                A spatial-temporal transformer structure for 3D human pose estimation.
              </p> -->
            </td>
          </tr>


          <tr onmouseout="mira_stop()" onmouseover="mira_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='mira_image'> -->
                  <!-- <img src='images/FedPEFT.JPG' width="160"></div> -->
                <img src='images/poseformer.JPG' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9343251">
                <papertitle>Mez: An Adaptive Messaging System for Latency-Sensitive Multi-Camera Machine Vision at the IoT Edge</papertitle>
              </a>
              <br>
              Anjus George,
              Arun Ravindran,
              <strong>Matias Mendieta</strong>,
              Hamed Tabkhi.
              <br>
              <em>IEEE Access, 2021
              <br>
              <a href="https://ieeexplore.ieee.org/document/9343251">paper</a>
              <!-- <a href="https://github.com/TeCSAR-UNCC/CARPe_Posterum">code</a> -->
              <p></p>
              <!-- <p>
                A spatial-temporal transformer structure for 3D human pose estimation.
              </p> -->
            </td>
          </tr>
          
          <tr onmouseout="mira_stop()" onmouseover="mira_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='mira_image'> -->
                  <!-- <img src='images/FedPEFT.JPG' width="160"></div> -->
                <img src='images/poseformer.JPG' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9020639">
                <papertitle>A Novel Application/Infrastructure Co-design Approach for Real-time Edge Video Analytics</papertitle>
              </a>
              <br>
              <strong>Matias Mendieta</strong>,
              Christopher Neff,
              Daniel Lingerfelt,
              Christopher Beam,
              Anjus George,
              Sam Rogers,
              Arun Ravindran,
              Hamed Tabkhi.
              <br>
              <em>IEEE SoutheastCon, 2019
              <br>
              <a href="https://ieeexplore.ieee.org/document/9020639">paper</a>
              <!-- <a href="https://github.com/TeCSAR-UNCC/CARPe_Posterum">code</a> -->
              <p></p>
              <!-- <p>
                A spatial-temporal transformer structure for 3D human pose estimation.
              </p> -->
            </td>
          </tr>

          <tr onmouseout="mira_stop()" onmouseover="mira_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='mira_image'> -->
                  <!-- <img src='images/FedPEFT.JPG' width="160"></div> -->
                <img src='images/poseformer.JPG' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/9020648">
                <papertitle>Measuring Compute-Reuse Opportunities for Video Processing Acceleration</papertitle>
              </a>
              <br>
              Andrew Willis,
              Hamed Tabkhi,
              <strong>Matias Mendieta</strong>,
              Christopher Neff.
              <br>
              <em>IEEE SoutheastCon, 2019
              <br>
              <a href="https://ieeexplore.ieee.org/document/9020648">paper</a>
              <!-- <a href="https://github.com/TeCSAR-UNCC/CARPe_Posterum">code</a> -->
              <p></p>
              <!-- <p>
                A spatial-temporal transformer structure for 3D human pose estimation.
              </p> -->
            </td>
          </tr>
					
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
